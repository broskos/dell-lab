parameter_defaults:
  CephConfigOverrides:
    max_open_files: 131072
    osd_recovery_op_priority: 2
    osd_recovery_max_active: 2
    osd_max_backfills: 1

  CephPoolDefaultSize: 2
  CephPoolDefaultPgNum: 32

  CephAnsibleExtraConfig:
    nb_retry_wait_osd_up: 60
    delay_wait_osd_up: 20
    is_hci: true
    # To limit CPU quota to a certain NUMA node
    # ceph_osd_docker_cpuset_cpus: "1,2,21,22,41,61"
    # cpu_limit 0 means no limit as we are limiting CPUs with cpuset above
    # If more than one CPU per Ceph OSD is required set the correct value
    # default ceph_osd_docker_cpu_limit: 1
    ceph_osd_docker_cpu_limit: 1
    # numactl preferred to cross the numa boundary if we have to but try to only use memory from numa node0
    # cpuset-mems would not let it cross numa boundary (boundary crossing is preferable to crashing)
    # lots of memory so NUMA boundary crossing unlikely
    ceph_osd_numactl_opts: "-N 1 --preferred=1"
  CephAnsibleDisksConfig:
    osd_scenario: lvm
    osd_objectstore: bluestore
  NodeDataLookup: |
    {
      "4c4c4544-0038-4d10-804a-cac04f395432": {
        "devices": [
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy0-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy1-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy2-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy3-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy4-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy5-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy6-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy7-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b39bd935ff-phy8-lun-0"
        ]
      },
      "4c4c4544-0038-4d10-804c-cac04f395432": {
        "devices": [
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy0-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy1-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy2-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy3-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy4-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy5-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy6-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy7-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3b664cfff-phy8-lun-0"
        ]
      },
      "4c4c4544-0038-4e10-8046-cac04f395432": {
        "devices": [
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy0-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy1-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy2-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy3-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy4-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy5-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy6-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy7-lun-0",
          "/dev/disk/by-path/disk/by-path/pci-0000:18:00.0-sas-exp0x500056b3c992d9ff-phy8-lun-0"
        ]
      }
    }
